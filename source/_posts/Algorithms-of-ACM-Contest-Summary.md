title: Algorithms of ACM Contest Summary
tags:
  - Algorithm
  - Summary
date: 2015-03-22 20:55:37
catagories:
---
*(2015/08/03 更新LCA/RMQ，KMP)*

四五年没有再去好好温习ACM方面的东西了，不过这一块其实时不时还是会提到，姑且做个简陋的算法方面的总结吧~时间精力有限，能总结多少是多少了。
这里写法同样是"复习用"。[NOCOW](http://www.nocow.cn/index.php/%E9%A6%96%E9%A1%B5)会比我说得更加详细清楚:P

##动态规划(背包/博弈/树状/字符串/状态压缩等)
动态规划，核心在于定义"状态"及"状态转移方程"。
<!--more-->

**背包**
有限空间内放置各种价值不同资源(物品)的最优值问题。这个问题[崔添翼大牛](https://github.com/tianyicui/)在《背包九讲》里面讲得超清楚，简单概括一下好了。

1.  01背包：各种物品只有一件。$F[i,v]=max\\{F[i-1,v],F[i-1,v-C\_i]+W\_i\\}$，即选择取或不取。循环每件物品时，如倒序扫描DP数组，可以降低一维空间复杂度。
2.  完全背包：各种物品无限件。$F[i,v]=max\\{F[i-1,v],F[i,v-C\_i]+W\_i\\}$。01背包改成顺序扫描DP数组就可以了。预处理去掉明显性价比低的物品，能进一步优化。
3.  多重背包：各种物品$M\_i$件。$F[i,v]=max\\{F[i-1,v-kC\_i]+kW\_i\\},0\le k\le M\_i$。可以将$M\_i$拆分成二进制表示的多件物品，进行01背包，优化复杂度。*单调队列优化容后补充*
4.  多维背包：以上问题扩展到多维有限空间。二维为例，$F[i,v,u]=max\\{F[i-1,v,u],F[i-1,v-C\_i,u-D\_i]+W\_i\\}$，多一重循环就好了，比如二维01背包就两重倒序扫描。
5.  分组背包：以上问题的物品分组，每组最多取一件。$F[k,v]=max\\{F[k-1,v],F[k-1,v-C\_i]+W\_i\\},i\in 组k$。先循环组，再倒序扫描DP数组每次取组内一件。
6.  有依赖的背包：以上问题选用物品要满足依赖关系，依赖关系是一个森林。由于每一个结点及其儿子都有$2^k$种选择，这相当于多次背包的结果再合并的问题。就用树状DP的方法，从叶子开始，每一个结点都进行一次01背包减少选择。

其他技巧：

*   定义状态，可以定义"花费刚好为v时的最优值"和"花费至多为v时的最优值"两种；
*   记录最优方案，则开多一个数组记录来源状态，及状态转移选择(如果来源状态不暗含的话)；
*   求方案总数，最小值等，则将max改成sum、min；
*   求第K优解，则在状态数组中多开一维(就是每个状态变一个队列)，记录前K优解。

**博弈**
博弈论的状态一般是很明显的，关键是要从胜负状态反推状态转移方程。

*   SG博弈：最经典的是NIM游戏。【待补充】。参见[这里](http://blog.csdn.net/logic_nut/article/details/4711489)

**树状**
一般从子结点开始归纳状态转移。这方面的总结太杂乱，【待补充】。

**序列/字符串**

*   最大子矩阵 悬线法

**插头**
二维平面，对连通性有要求，逐格进行状态转移的DP，并且每个格子的状态需要进行压缩。
压缩方法包括：
1. 连通的格子用同一标号表示。
2. 路线不能交叉，标号只用两个就够。
3. 扩大成使用$2^k$进制，位运算来转移
更多介绍见[论文PPT](http://wenku.baidu.com/view/4fe4ac659b6648d7c1c74633.html)

**相关优化**

*   滚动数组：因为动态规划方程中，最外层循环每次往往只需要用到上一次循环的数据，所以只开能够存下两次大循环的空间就好，而不是全部循环的空间。
*   状态压缩：
*   单调队列：一般应用于状态转移中，要求旧状态带有"最大/最小"条件的问题。关键是发现可以抛弃掉的、更老的状态，作为单调队列可抛弃的状态。对于有区间限制的题目，可以将{状态值，状态位置}对建成单调双端队列，左限制右求最值。每次状态转移时就可以从单调队列中提取，而不必往前扫描。没有区间限制求第k大/k小的题目，若发现了可抛弃的状态，亦可构建一个单调序列，用二分查找提取(最长不下降子序列)。[见此总结](http://www.cnblogs.com/neverforget/archive/2011/10/13/ll.html)
*   优先队列/堆优化：

【考虑补充：四边形不等式优化】

##树与图论(最短路/生成树等)

**Adjacency List**
![](http://i57.tinypic.com/2czavls.jpg)

**Topological Sort**
BFS每次向有序序列中加入入度为0的点，并删除所有从它出发的边，若删的时候有边指回已经加入序列的点就有环路。或DFS，递归完时再将点加入有序序列(倒序)，若DFS到已经在DFS里面的点就有环路。一个图可能存在多种拓扑排序结果。
**Huffman Codes**
使用不定长个二进制位来表达字符串的一个字母(单位)以尽可能压缩字符串。相当于只计算叶结点代价和的最优二叉搜索树。每次从优先队列中取代价最小的两颗子树合并就好。
**LCA/RMQ问题 - Tarjan/Sparse Table**

* RMQ(区间最值查询)问题可使用在线的Sparse Table法，本质是一种动态规划。F[i, j]表示i起点2^j长度的区间内的最值，F[i, j]=opt{F[i, j-1], F[i+2^j-1, j-1]}，查询的时候查询重叠的两个边界子区间如opt[3,8]=opt{F[3,2],F[5,2]}。每次插入时修改相关的区间就好，O(nlogn)预处理O(1)查询。或者用线段树解决O(n)预处理O(logn)查询。
* LCA(最近公共祖先)问题可使用离线的Tarjan法，DFS遍历每一个点，并使用并查集记录遍历过程，遍历完了一个点及其子树后就处理与之相关的查询。如果另一端也处理过了，答案就是并查集根（要么是兄弟子树上的，其并查集根就是父亲，要么是自身子树上的，合并后并查集根就是自己）。

两个问题可以互相转化，求RMQ问题就相当于求按原序列为中序的堆的LCA问题，求LCA问题就相当于该树中序遍历序列的相应两个点之间的RMQ问题。
**强连通分支问题 - Kosaraju**
有向图求强连通分支(任意点相互可达)的算法。先DFS一次记录访问顺序，然后所有边取反，逆访问顺序多次DFS，每次DFS到的点即为一个强连通分支。

*   类似的算法还有Tarjan和Gabow，不过时间复杂度的优化并不算2太大，暂时不写啦

---------------

**Dijkstra**
正权图单源最短路，以贪心为基础。维护一个数组，记录源点到每个点当前已知最短路边权和，初始除了源点全为无穷大。循环V次，每次取数组中的最小值，即为到该对应点的最短路。$O(V^2)$

*   也可以用邻接表保存边，维护一个二叉堆而不是数组。$O((E+V)logV)$

**Bellman-ford**
任意图单源最短路。遍历V-1次边集进行松弛。如果遍历后还有边可以松弛，则存在负权环。$O(VE)$

**SPFA**
用队列优化Bellman-ford算法。一开始只有源点在队列中。每次循环遍历队头的点的邻边，所有被松弛的点加入队列。如果某个点的入队次数超过V，则存在负权环。

*   SLL优化：对于要入队的元素i，队首j，若$dist[i] < dist[j]$，i插入队首； 
*   LLL优化：队首j，若$dist[j] < average(dist[])$，j延至队尾处理； 

其中dist[i]是到第i个点的当前最短路(边权和)。核心思路是提前可能更优的松弛。加上两个优化平均可提速50%。

**Floyd-warshall**
任意图多源最短路，动态规划为基础。维护一个邻接矩阵，三重循环，每次以对角线的点为中心作十字用v[i,k]+v[k,j]更新v[i,j]。$O(V^3)$

**Johnson**
任意图多源最短路，稀疏图上比Floyd表现好。正权图直接每个点出发各跑一遍堆优化Dijkstra。带负权图先设一个到所有点都有权0的边的新点s，跑一遍s出发的Bellman-ford/SPFA求得最短距离h[v]，然后原来的每条边e[u,v]+=h[u]-h[v]，再重复开始正权图步骤。

---------------

**Prim**
任意图的最小生成树算法。维护一个数组，记录每个"已到点"连接某个"未到点"的最小边权。循环V次，每次取数组中的最小值，对应边即为最小生成树树枝，对应点加入"已到点"。$O(V^2)$

*   也可以用邻接表保存边，维护一个二叉堆而不是数组，但写这个不如写Kruskal。$O((E+V)logV)$

**Kruskal**
任意图的最小生成树算法。边集按权值从小到大排序逐条尝试加入解，并维护一个并查集以保证不形成环路，直到成功加入V-1条边。$O(VlogV+ElogE)$

【考虑补充：次小生成树/K短路】

##网络流(二分图匹配等)
重要定理：最大流=最小割。
**Ford-Fulkerson**
网络流算法的基础思想。不断简单地DFS寻找一条增广路。
**Edmonds-Karp**
每次BFS出一条长度最短的增广路。BFS时使用临时数组推演可能作出的流量变化。
**Dinic** 
优化后的求最大流算法。每次先BFS建立层次图(离源点距离i的点在第i层)，然后DFS逐层递归找一条增广路(能增加流量的路径，流量为路径中权值最小的边)，然后增广值加入总流量，并把整条增广路反向。循环至汇点不能到达。动画及代码见[这里](http://comzyh.com/blog/archives/568/)。
**SAP**
相比Dinic，常数上更快但是代码行数和细节更多的算法。初始化时先BFS建立层次图（SAP是里汇点的距离）。然后循环进行原点出发的回溯(DFS写成while)来寻找增广路。每条可行弧必须刚好降一层。如果某个点没有可行弧，就更新它的层次值为min{它可以去的相邻点的层次值}，再继续回溯。直到没有属于某个中间层次的点出现断层，或者源点层次值大于等于点数n了。评价见[这里](http://fanhq666.blog.163.com/blog/static/81943426201072554322479/)。
**Hungarian**
求最大二分图匹配的算法。左半部每个点依次贪心，每次出发递归寻找右边一个可增广的未连接点后即可(递归过程中可以标记一下，每个点只需要访问一次)。
**Kuhn-Munkres**
求带权二分图的最佳匹配(权和最大)的算法。每个点设一个点权L，先左半部$L[X\_i]=max\\{e\_{ij}\\}$，右半部$L[Y\_j]=0$。同样每次从$X\_i$出发，用匈牙利算法找所有边满足$L[i]+L[j]=e\_{ij}$的"等值子图"的增广路，找增广路时右半部每个点记录$slack[Y\_j]=max\\{L[i]+L[j]-e\_{ij}\\}$。如果找不到增广路，令$d=min\\{slack[Y\_j]\\}$，找增广路过程中访问到的每个点$L[X\_i]=L[X\_i]-d, L[Y\_j]=L[Y\_j]+d$，未访问点$slack[Y\_j]=slack[Y\_j]-d$，再循环匈牙利算法直至找同一个点的增广路。最后找到等值子图的完全匹配(就是每个点都匹配到)就是解。$O(n^3)$

##数据结构(包括线段树等)

**Monotonic Queue**
一个双端队列，左边抛掉不符合新条件的旧元素，右边新元素入队时抛掉不能保持单调性的。
能够求最大最小/k大k小问题。经常被用于优化动态规划算法。
**Segmentation tree**
一个结点记录一条线段的值，子结点将父结点代表线段对半分。由于对半分的特性，线段树是完全二叉树，每个结点表示的线段可以推导出(作为递归参数)而不必记录。更新/询问时要么递归下去直到叶结点。要么lazy优化，结点线段被包含在要求线段之内就好。如果有必要就记录这个结点这次更新的值。下次需要更加细化地更新/询问时，再将这个值往下推。反正因为包含关系，叶结点更新的量是一样的。
二维问题也可能用到线段树(扫描线法)，如求矩形面积叠合后和，x轴作为离散化的线段建立线段树，然后按y轴顺序往树上添加矩形的上底和下底，并记录每条线段目前是被上底覆盖还是下底覆盖，这样添加的时候就可以算面积。参考[这里](http://notonlysuccess.me/?p=978)。
**Disjoint Set**
数组记录的树，记录父结点及子树元素个数。查找：递归查找出树根a，然后沿路将父结点全部置为a。合并：要合并的两个结点分别查找出树根a,b，然后元素少的树根a父结点置为b

---------------

**BST**
搜索树是一系列方便快速查找的数据结构。最简单的BST，左儿子小右儿子大，建树、插入、查找都是从树根开始的递归。删除则是该结点与左子树的最大结点互换后删除（因为这个结点不可能有两棵子树。如果换右子树最小也可以）
**AVL**
左右子树深度差最多是1。在BST的操作以外，插入完后往上一层算平衡度(左树高减右树高)，如果要进行平衡，看被插入的子子树相对该结点位置。如果路径是LL或RR就单旋，如果是RL或LR就双旋(比如先在儿子左旋，再在该结点右旋)。删除也一样。
每次插入至多只需要做一次单旋或双旋。删除删成链状的话可能要两次。不过不想写那么细节的话还是都检查并更新了吧。
所有操作平均及最坏情况都是O(logN)。旋转平均只需O(1)。
**Splay**
思路是将要访问的结点比较平衡地旋转(Splay)到树根，这样访问比较频繁的结点都在树根附近。和AVL一样是看结点、父结点和祖父结点的走向关系，LL/RR就单旋/连续单旋(Zig/Zig-Zig)，LR/RL就双旋(Zig-Zag)。插入/查找都是旋转该点到根结点。删除则是把替换前的父结点旋转到根结点(有其他算法变种)。分裂是把作为分裂界的结点旋转到树根后切掉左子树或右子树变成一大一小两棵树。合并的话两棵树必须一大一小，把小树的最大元素旋转到根然后合并。
虽然单次最坏情况可能有O(n)，均摊复杂度也是O(logN)。长远来看比AVL平均更快，代码比AVL简单，还支持合并和拆分，不过不能用于并行环境中。
**Red-Black**
将结点分为红黑两类，所有空结点视为黑的叶结点，要求红结点必须连着黑结点，所有根到叶的路径黑结点数必须相同，而且根是黑结点。
插入时，插入点设为红。若父结点和兄弟同红，把父结点和兄弟变黑，祖父变红，然后回溯考虑祖父，直到1.父结点和兄弟异色，类似AVL，插入点是外儿子就做单旋/内儿子双旋，旋上去的结点为黑，另外两结点为红；2.父结点为黑；3.或已经到了根结点直接变为黑。
删除时，先按BST交换数据删除，若被删位置与其儿子一红一黑，把儿子涂黑放上来就好。如果都是黑，考虑放上来后的兄弟S及其内外儿子。若S及儿子全黑，变为父亲P黑S红。若仅S内子(RL/LR)红就双旋，其他情况(S/外子有红)单旋，新根与P换色，原来S的位置变黑。
以上过程已据Wiki简化，写起来还是略复杂，不过平衡度要求没有AVL严格。所以插入和删除相比更快，而查找更慢。
**Treap**
每个结点插入时加上一个随机的优先级，要求结点值满足BST性质同时优先级值满足堆性质。插入时比较插入结点和父结点的优先级，进行左旋或右旋。删除时则比较两个儿子的优先级，将要删除结点往下旋到叶结点删除。分裂时将分裂界插入并给予最大/最小优先级让它成为新根，一左一右就分好了。合并时比如A树根结点优先值小，A根为新根，B树根据A根分裂，然后递归合并A左子树和B裂后小子树，右子树和裂后大子树分别为新左右子树。没AVL平衡，有常数时间上差异，但代码比AVL等简单很多。
**SBT**
出于陈启峰大神的[论文](https://github.com/lshain/book/blob/master/IOI%E8%AE%BA%E6%96%87/%E5%9B%BD%E5%AE%B6%E9%9B%86%E8%AE%AD%E9%98%9F2007%E8%AE%BA%E6%96%87%E9%9B%86/day1/10.%E9%99%88%E5%90%AF%E5%B3%B0%E3%80%8ASize%20Balanced%20Tree%E3%80%8B.pdf)。保证每棵子树的Size比另一边子树的任意子树(也就是"孙树")Size大。若外孙树大，单旋后依次递归旋下去的根和新根；若内孙树大，双旋后依次递归新的两个儿子和新根。
代码简单，同时因为记录了子树大小，可以很快找到第k大元素。
**Scapegoat Tree**
**B(B-), B+, B* Tree**
B(B-)：$M$叉树，根有$[2,\ M]$个儿子，其他内点$[\ \lceil M/2 \rceil,\ M]$个儿子，叶结点同高，遵循BST左小右大的原则，一个结点"儿子数-1"个值升序排列，每个值作为子树的值的分隔界(key)，并在树中只出现一次。插入时一个结点放不下了，就分裂，中间作key的值放到父亲里面，如此递归。删除时将要删的值和左子树最大值(在叶结点)交换。叶结点删了后若其左右兄弟的值有多，兄弟最大/最小值上移key拿下来，否则合并兄弟和key再递归此问题到父结点。
- B+：相比B树，所有值都在叶结点出现一遍，内结点仅记录当前作为分隔界的值。且叶结点相互链接以方便连续访问一片值。插入时是把分裂出的新结点的最小值复制到内结点作为key，删除是直接找叶结点的值，其他同B树。
- B\*：相比B树，保证每个结点$\frac{2}{3}M$的值是满的。值太多先让兄弟保留，兄弟保留不下再二裂为三。

因为叉数多，深度浅，适用于访问结点代价昂贵的场合，如硬盘/数据库的读写。用数组存key会有不少空位，浪费空间，但在查找时可以用二分；用链表牺牲了查找效率但插入和删除比较方便一点。相比较而言，B树在记录每个子树大小后能快速访问第k大的点，B+树适合连续访问一片数据，B\*比B-操作复杂但能节省空间。
**Optimal Binary Search Tree**
用于无插入和删除，知道每个值搜索概率的静态查找。设树中每个点代价=深度\*概率(点权)，总代价是所有点代价和(Huffman Code是叶结点代价和)。因此用动态规划构建完全二叉树，状态为以序列第i个值开始的连续K个结点构建，状态转移时记录上一个状态来源，由此构建好树。
**Trie**
每个点表示一个字母，或者二进制里面一位。根为空，从根走到某结点表示一个单词或数字，并在末尾结点存其相应属性的树。数据稠密，长度不大或可以并行处理的情况下可能比Hash表表现的好而且不用考虑冲突或hash法。不过比Hash表更费空间。
**Suffix Tree**
- 朴素：先在最后加一个字符串中没有的字符，然后对字符串的每个后缀串建立Trie，这样所有后缀都在叶结点上。然后对所有单儿子的路径压缩成一点。
- Ukkeonen：【待补充】
- 倍增：【待补充】

因为Trie可进行前缀搜索，而后缀树又在Trie上存了所有后缀，还为后缀属于哪个字符串做了标识，因此可用于查找出现次数/重复次数/最长重复/最长回文/最长公共字串(两个字符串连起来做后缀树)等问题上。
**Binary Indexed Tree**
**Link-Cut Tree**
**Finger Tree**

---------------

下面全部以小根堆为例，大根堆同理。除了基本的二叉堆没有合并操作外，其他堆结构基本都以合并操作为核心，插入等同合并，删除根等同合并子树，删除其他结点（注意这必须指定，堆本意就没打算查找最小结点以外的结点）则相当于把该节点的值改成无穷小，然后进行删除根操作（或者原地删除后合并子树并往上递归保证特定的堆性质）。
性能评价方面，堆查找最小都是O(1)，二叉堆没有合并且最坏O(N)，斜堆都是O(logN)的，左式堆常数上更优，二项堆插入均摊为了O(1)，Fibonacci堆删除以外都是O(1)。
**Binary Heap**
顶上是最小值，且每个子树都满足这个堆性质。用完全二叉树结构(数组存就好)，插入时插到最后然后上滤(递归地跟父结点比较)，删除时和队尾交换然后新根下滤，改小/改大分别则上滤/下滤。建堆则从最后一个非叶结点开始逐个下滤，直到根结点。
**Skew Heap**
二叉堆之余定义了特别的合并操作，无条件交换每层左右子树。合并时对于根小的堆A，其根作为新根，A右子树成为新左子树，然后递归A左子树和另一个堆的合并。
（非递归版合并：所有堆沿最右路径切片，形成的子树按堆根从小到大排序，每次最小堆变次小的堆左树，原左树变右树，然后排序继续）
**Leftist Heap/左偏树**
每个点记录到最近叶结点的距离，左子树的距离一定不小于右子树。合并时根小的堆A及其左子树保留，递归合并右子树和根大的堆，然后从下往上把不满足左偏性质的左右交换。
**Binomial Heap(Queue)**
每个二项堆实际是一个树序列(森林)，序列中i位置(中间可能有空位)是结点数为2^i的i叉树。合并时就相当于从序列低位到高位实行二进制加法，每棵树上的合并则是简单地让根值大的树直接作为根值小的树的子树(如果此前有进位，进位直接作为新堆该位的树)。可以通过在合并(包括插入和删除)时记录最小值所在的位置，从而让查找与其他堆一样是O(1)的。
**Fibonacci Heap**
核心思想是尽可能地延后各种操作。也是一个树序列(一般用双向链表表达序列和树每一层)。合并时宏观上一直合并到所有树大小不同(用一个以树大小为index的数组扫描)，微观上也是根大的直接做根小的子树。插入时直接放入序列不进行合并。改小内结点时，该结点为根的树放到序列上，然后mark父亲，父亲若mark过了，父亲为根的树也放上去然后再递归祖父。

##数学&几何(凸包等)

##思路/基本功(二分答案/贪心/搜索/排序等)

**排序算法**

ACM非常少用到，姑且就当算法课基础复习了

*   Bubble：每次第i个元素网上冒泡。稳定。
*   Insertion：每次第i个元素在已排序元素中找到应插入位置，后面的已排序元素逐个后移。稳定。
*   Selection：每次选未排序元素中的最大的，与数组最前面元素交换。不稳定。
*   Shell：设一个增量，相隔是增量的倍数的为同一组，分组插入排序；增量不断折半。不稳定。复杂度略大于O(NlogN)。
*   Quick：每次选一个Key，左右两端各自扫描，小于Key的放一边，大于Key的放另一边，扫描index仍未交错则交换元素，递进index继续扫描，递归分治此过程。Key的选择可以是固定，或优化为随机 / 前中后三元素比较选中值        。不稳定。
*   Heap：建堆(从倒数第二层开始倒着逐个下滤)，逐个删掉根结点(下滤)，删完的数组就是了。
*   Merge：分治到底回溯归并，每层用临时数组归并两端，再把归并好的值放回去。不稳定。
*   Radix：顺序循环每一个十进制位，每次根据该位数字放入桶中再连起来。稳定。复杂度O(dN)，近似O(NlogN)。
*   Bin：将数据根据关键字分发到多个有序桶中，桶内有多个元素再进行上述的比较排序。稳定。
*   Intro：开始采用快速排序算法进行排序,当递归达到一定深度时就改为堆排序来处理。

**字符串匹配算法**

*   KMP：思路是匹配到某个位置失败了，可根据此时模式串后缀和前缀的相等关系跳过一段。为模式串p引入一个数组next，若next[i]=k，每次待匹配串和模式串的第i位匹配失败时，可继续递归匹配模式串的p[next[i]]位。优化后的KMP算法next数组构建举例如图。
![](http://i60.tinypic.com/2wd4mrb.jpg)
*   Sunday(http://blog.csdn.net/WINCOL/article/details/4795369)

**Hash Table**

**搜索算法及技巧**

* 深度限制DFS
* 双向BFS
* A*
* 记忆化搜索?

**C++ STL**
虽然STL和算法无关，但是由于STL的存在，很多数据结构不用自己写，是ACM比赛中必备外挂……

容器：操作包括begin, end, rbegin, rend, erase(,), clear
**1. 标准序列容器**：
`list<>` `vector<>` `deque<>`，内存分配分别是连续，小片连续，不连续。
常用操作（各类略有出入请自行琢磨，下同）: empty, front, back, push\_front(), push\_back(), pop\_front, pop\_back, max\_size, reverse, insert(,,), remove(), remove\_if(), assign(,), swap(), at(), unique, sort

**2. 标准关联容器**：
`set<>` `multiset<>` `map<,>` `multimap<,>`，对应集合，可重复集合，一对一映射，一对多映射。红黑树实现。


**3. 容器适配器**：
标准序列容器变种，提供受限的底层容器接口，没有迭代器
`queue<int>` `queue<int,list<int>>`，默认deque作为底层容器，包括操作push,pop,front,back,empty,size
`priority_queue<int>` `priority_queue<int, vector<int>, greater<int>>`，默认使用vector作为底层容器，包括操作top,push,pop,empty,size
`stack<>`
**4. 似容器**：
`string<>` `valarray<>` `bitset<>`
**5. 容器迭代器**：
`vector<int>::iterator` `vector<int>::const_iterator`

算法：
1. 以下内容需要`#include <algorithm>`
sort(begin,end,cmp), 相比c的qsort，用的是intro_sort，不会退化
2. 以下内容需要`#include <functional>`
greater<> 【待补充】[见这里](http://www.baidu.com/s?ie=utf8&oe=utf8&wd=C%2B%2B%20greater&tn=90128732_hao_pg&ch=2&lans=132),[以及这里](http://wenku.baidu.com/link?url=FQ_M_OG2UgNqJLngZgSQlAeek-0B21j9QoMkvUgrmdq9W1TWoqotNGEvVUuqDn1NdqsBMmntGyyPcsDMj3gVJsLhCRolj2OZxBTnkc0-2Ii)
less<>

**均摊时间复杂度分析(potential method)**

算法可视化参考：
https://www.cs.usfca.edu/~galles/visualization/Algorithms.html


